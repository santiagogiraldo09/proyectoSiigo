import streamlit as st
import pandas as pd
import io
import numpy as np
import locale
from datetime import datetime
import requests
from msal import ConfidentialClientApplication
import zipfile
import openpyxl

# ==============================================================================
# CONFIGURACIÃ“N DE SHAREPOINT Y AZURE
# ==============================================================================
CLIENT_ID = "b469ba00-b7b6-434c-91bf-d3481c171da5"
CLIENT_SECRET = "8nS8Q~tAYqkeISRUQyOBBAsLn6b_Z8LdNQR23dnn"
TENANT_ID = "f20cbde7-1c45-44a0-89c5-63a25c557ef8"
SHAREPOINT_HOSTNAME = "iacsas.sharepoint.com"
SITE_NAME = "PruebasProyectosSantiago"
RUTA_CARPETA_VENTAS_MENSUALES = "Ventas con ciudad 2025"
# ==============================================================================
# FUNCIONES DE AUTENTICACIÃ“N Y CONEXIÃ“N
# ==============================================================================
AUTHORITY = f"https://login.microsoftonline.com/{TENANT_ID}"
SCOPES = ["https://graph.microsoft.com/.default"]

def actualizar_archivo_trm(headers, site_id, ruta_archivo_trm, df_datos_procesados, status_placeholder):
    """
    Actualiza la hoja "Datos" del TRM.xlsx preservando fÃ³rmulas, formatos y otras hojas.
    TambiÃ©n evita las columnas "Unnamed:".
    """
    nombre_hoja_destino = "Datos"
    status_placeholder.info(f"ðŸ”„ Iniciando actualizaciÃ³n avanzada de la hoja '{nombre_hoja_destino}'...")

    try:
        # PASO 1: Descargar el archivo TRM
        status_placeholder.info("1/4 - Descargando archivo TRM...")
        endpoint_get = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_archivo_trm}"
        response_get = requests.get(endpoint_get, headers=headers)
        response_get.raise_for_status()
        contenido_trm = io.BytesIO(response_get.content)

        # PASO 2: Leer los datos y preparar el nuevo bloque
        status_placeholder.info("2/4 - Leyendo datos existentes y preparando nuevas filas...")
        df_trm_existente = pd.read_excel(contenido_trm, sheet_name=nombre_hoja_destino, engine='openpyxl')
        df_trm_existente.reset_index(drop=True, inplace=True)
        
        # LÃ³gica para crear el bloque de datos a agregar (columnas A,B,C en blanco)
        lista_nuevas_filas = []
        nombres_columnas_destino = df_trm_existente.columns
        nombres_columnas_origen = df_datos_procesados.columns
        for index, fila_origen in df_datos_procesados.iterrows():
            nueva_fila = {}
            nueva_fila[nombres_columnas_destino[0]] = "" # Columna A en blanco
            nueva_fila[nombres_columnas_destino[1]] = "" # Columna B en blanco
            nueva_fila[nombres_columnas_destino[2]] = "" # Columna C en blanco
            for i, col_destino in enumerate(nombres_columnas_destino[3:]):
                if i < len(nombres_columnas_origen):
                    nueva_fila[col_destino] = fila_origen[nombres_columnas_origen[i]]
            lista_nuevas_filas.append(nueva_fila)
        
        df_para_agregar = pd.DataFrame(lista_nuevas_filas)
        df_trm_actualizado = pd.concat([df_trm_existente, df_para_agregar], ignore_index=True)

        # --- SOLUCIÃ“N PARA COLUMNAS "Unnamed:" ---
        # Busca columnas que empiecen con "Unnamed:" y las elimina.
        cols_a_eliminar = [col for col in df_trm_actualizado.columns if 'Unnamed:' in str(col)]
        if cols_a_eliminar:
            df_trm_actualizado.drop(columns=cols_a_eliminar, inplace=True)
            status_placeholder.info("ðŸ§¹ Columnas 'Unnamed:' eliminadas.")

        # PASO 3: Escribir los datos en el libro de Excel preservando todo lo demÃ¡s
        status_placeholder.info("3/4 - Modificando el archivo Excel en memoria...")
        # Volvemos al inicio del buffer para que openpyxl pueda leerlo
        contenido_trm.seek(0)
        
        # Cargar el libro de trabajo completo con openpyxl
        libro = openpyxl.load_workbook(contenido_trm)
        hoja = libro[nombre_hoja_destino]
        
        # Borrar datos antiguos de la hoja (excepto encabezados)
        for r in range(hoja.max_row, 1, -1):
            hoja.delete_rows(r)
            
        # Escribir los datos del DataFrame actualizado
        from openpyxl.utils.dataframe import dataframe_to_rows
        for r_idx, row in enumerate(dataframe_to_rows(df_trm_actualizado, index=False, header=False), 2):
            for c_idx, value in enumerate(row, 1):
                hoja.cell(row=r_idx, column=c_idx, value=value)

        # PASO 4: Guardar el libro modificado y subirlo
        status_placeholder.info("4/4 - Subiendo archivo final a SharePoint...")
        output = io.BytesIO()
        libro.save(output)
        
        endpoint_put = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_archivo_trm}:/content"
        response_put = requests.put(endpoint_put, data=output.getvalue(), headers=headers)
        response_put.raise_for_status()

        status_placeholder.success("âœ… Â¡Archivo TRM actualizado preservando fÃ³rmulas y formatos!")
        return True

    except Exception as e:
        status_placeholder.error(f"âŒ FallÃ³ la actualizaciÃ³n del archivo TRM. Error: {e}")
        return False

def validar_respuesta_sharepoint(response, nombre_archivo):
    """
    Valida que la respuesta de SharePoint sea correcta y contenga un archivo Excel
    """
    st.info(f"ðŸ” Validando respuesta para: {nombre_archivo}")
    
    # 1. Verificar cÃ³digo de estado HTTP
    st.write(f"ðŸ“Š CÃ³digo HTTP: {response.status_code}")
    
    if response.status_code != 200:
        st.error(f"âŒ Error HTTP {response.status_code}")
        try:
            error_json = response.json()
            st.json(error_json)
        except:
            st.error(f"Texto de respuesta: {response.text[:500]}...")
        return False, "Error HTTP"
    
    # 2. Verificar el tamaÃ±o del contenido
    content_length = len(response.content)
    st.write(f"ðŸ“ TamaÃ±o del archivo descargado: {content_length:,} bytes")
    
    if content_length == 0:
        st.error("âŒ El archivo estÃ¡ vacÃ­o (0 bytes)")
        return False, "Archivo vacÃ­o"
    
    if content_length < 100:  # Un Excel vÃ¡lido debe tener al menos algunos cientos de bytes
        st.warning("âš ï¸ El archivo es muy pequeÃ±o para ser un Excel vÃ¡lido")
        st.write(f"Contenido recibido: {response.content}")
        return False, "Archivo muy pequeÃ±o"
    
    # 3. Verificar el Content-Type si estÃ¡ disponible
    content_type = response.headers.get('Content-Type', 'No especificado')
    st.write(f"ðŸ“‹ Content-Type: {content_type}")
    
    # 4. Verificar las primeras bytes para asegurar que es un archivo Excel
    primeros_bytes = response.content[:20]
    st.write(f"ðŸ”¢ Primeros 20 bytes (hex): {primeros_bytes.hex()}")
    
    # Un archivo Excel (.xlsx) debe comenzar con la signature de ZIP: "PK"
    if not response.content.startswith(b'PK'):
        st.error("âŒ El archivo no tiene la signature de un archivo ZIP/Excel vÃ¡lido")
        st.error("Los archivos .xlsx deben comenzar con 'PK' (signature de ZIP)")
        
        # Mostrar el inicio del contenido como texto para debug
        try:
            inicio_texto = response.content[:200].decode('utf-8', errors='ignore')
            st.error(f"Inicio del contenido como texto: {inicio_texto}")
        except:
            st.error("No se pudo decodificar el inicio del contenido como texto")
        
        return False, "Signature invÃ¡lida"
    
    st.success("âœ… El archivo parece ser un Excel vÃ¡lido")
    return True, "VÃ¡lido"

def obtener_contenido_archivo_sharepoint(headers, site_id, ruta_archivo):
    """
    Descarga un archivo especÃ­fico de SharePoint con validaciones completas
    """
    st.info(f"ðŸ“¥ Descargando archivo: {ruta_archivo}")
    
    # Construir el endpoint
    endpoint_get = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_archivo}:/content"
    st.write(f"ðŸ”— Endpoint: {endpoint_get}")
    
    try:
        # Realizar la peticiÃ³n
        response_get = requests.get(endpoint_get, headers=headers)
        
        # Validar la respuesta
        es_valido, mensaje = validar_respuesta_sharepoint(response_get, ruta_archivo.split('/')[-1])
        
        if not es_valido:
            st.error(f"âŒ ValidaciÃ³n fallÃ³: {mensaje}")
            return None
        
        return response_get.content
        
    except requests.exceptions.RequestException as e:
        st.error(f"âŒ Error de red al descargar el archivo: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ Error inesperado: {e}")
        return None

def verificar_archivo_existe_sharepoint(headers, site_id, ruta_archivo):
    """
    Verifica si un archivo existe y obtiene sus metadatos antes de descargarlo
    """
    st.info(f"ðŸ” Verificando existencia de: {ruta_archivo}")
    
    # Endpoint para obtener metadatos del archivo (sin descargar el contenido)
    endpoint_metadata = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_archivo}"
    
    try:
        response = requests.get(endpoint_metadata, headers=headers)
        
        if response.status_code == 200:
            metadata = response.json()
            
            nombre = metadata.get('name', 'Sin nombre')
            tamano = metadata.get('size', 0)
            tipo = metadata.get('file', {}).get('mimeType', 'No especificado')
            modificado = metadata.get('lastModifiedDateTime', 'No especificado')
            
            st.success(f"âœ… Archivo encontrado: {nombre}")
            st.write(f"ðŸ“ TamaÃ±o: {tamano:,} bytes")
            st.write(f"ðŸ“‹ Tipo MIME: {tipo}")
            st.write(f"ðŸ“… Ãšltima modificaciÃ³n: {modificado}")
            
            # Verificar que sea realmente un archivo Excel
            if tipo and 'spreadsheet' not in tipo.lower() and 'excel' not in tipo.lower():
                st.warning(f"âš ï¸ Advertencia: El tipo MIME '{tipo}' no parece ser un Excel")
            
            return True, metadata
        else:
            st.error(f"âŒ Archivo no encontrado. HTTP {response.status_code}")
            try:
                error_json = response.json()
                st.json(error_json)
            except:
                st.error(f"Respuesta: {response.text}")
            return False, None
            
    except Exception as e:
        st.error(f"âŒ Error al verificar archivo: {e}")
        return False, None


def get_access_token(status_placeholder):
    status_placeholder.info("âš™ï¸ Paso 2/5: Autenticando con Microsoft...")
    app = ConfidentialClientApplication(
        client_id=CLIENT_ID,
        authority=AUTHORITY,
        client_credential=CLIENT_SECRET
    )
    result = app.acquire_token_for_client(scopes=SCOPES)
    if "access_token" in result:
        st.success("âœ… Token de acceso obtenido con Ã©xito.")
        return result['access_token']
    else:
        st.error(f"Error al obtener token: {result.get('error_description')}")
        return None

def get_sharepoint_site_id(access_token):
    headers = {'Authorization': f'Bearer {access_token}'}
    site_url = f"https://graph.microsoft.com/v1.0/sites/{SHAREPOINT_HOSTNAME}:/sites/{SITE_NAME}"
    try:
        response = requests.get(site_url, headers=headers)
        response.raise_for_status()
        site_id = response.json().get('id')
        st.success(f"âœ… ConexiÃ³n exitosa con el sitio SharePoint: '{SITE_NAME}'")
        return site_id
    except requests.exceptions.RequestException as e:
        st.error(f"Error al obtener site_id: {e.response.text}")
        return None

def encontrar_archivo_del_mes(headers, site_id, ruta_carpeta, status_placeholder):
    """
    Busca dentro de una CARPETA especÃ­fica y devuelve la RUTA COMPLETA del archivo del mes.
    """
    try:
        # Meses en espaÃ±ol con diferentes variaciones
        fecha_actual = datetime.now()
        mes_numero = fecha_actual.month
        
        # Diferentes patrones que podrÃ­a tener el archivo
        patrones_busqueda = [
            f"{mes_numero}. ",  # "9. " para septiembre
            "Septiembre",       # Nombre completo del mes
            "septiembre",       # MinÃºscula
            f"{mes_numero:02d}",# "09" con cero delante
        ]
        
        st.info(f"ðŸ” Buscando archivo del mes {mes_numero} (Septiembre) en: '{ruta_carpeta}'")
        st.write(f"Patrones de bÃºsqueda: {patrones_busqueda}")
        
        # Primero, listar TODOS los archivos en la carpeta
        st.write("ðŸ“‚ Listando todos los archivos disponibles:")
        endpoint_children = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_carpeta}:/children"
        response_list = requests.get(endpoint_children, headers=headers)
        
        if response_list.status_code == 200:
            todos_archivos = response_list.json().get('value', [])
            
            st.write(f"ðŸ“Š Total de archivos en la carpeta: {len(todos_archivos)}")
            
            # Mostrar todos los archivos para debug
            for item in todos_archivos:
                if not item.get('folder'):  # Solo archivos, no carpetas
                    nombre = item.get('name', '')
                    tamaÃ±o = item.get('size', 0)
                    st.write(f"ðŸ“„ {nombre} ({tamaÃ±o:,} bytes)")
            
            # Buscar el archivo que coincida con los patrones
            archivos_candidatos = []
            
            for item in todos_archivos:
                if item.get('folder'):  # Saltar carpetas
                    continue
                    
                nombre_archivo = item.get('name', '').lower()
                
                # Verificar cada patrÃ³n
                for patron in patrones_busqueda:
                    if patron.lower() in nombre_archivo:
                        archivos_candidatos.append({
                            'nombre_original': item.get('name'),
                            'ruta_completa': f"{ruta_carpeta}/{item.get('name')}",
                            'tamaÃ±o': item.get('size', 0),
                            'patron_encontrado': patron
                        })
                        break  # Salir del loop de patrones una vez encontrado
            
            if archivos_candidatos:
                st.success(f"âœ… Encontrados {len(archivos_candidatos)} archivos candidatos:")
                
                for i, candidato in enumerate(archivos_candidatos):
                    st.write(f"{i+1}. **{candidato['nombre_original']}** ({candidato['tamaÃ±o']:,} bytes) - PatrÃ³n: '{candidato['patron_encontrado']}'")
                
                # Seleccionar el primer candidato (o puedes agregar lÃ³gica mÃ¡s sofisticada)
                archivo_seleccionado = archivos_candidatos[0]
                st.success(f"ðŸŽ¯ Archivo seleccionado: **{archivo_seleccionado['nombre_original']}**")
                
                return archivo_seleccionado['ruta_completa']
            else:
                st.warning(f"âš ï¸ No se encontraron archivos que coincidan con los patrones para el mes {mes_numero}")
                
                # Mostrar sugerencia
                st.info("ðŸ’¡ Archivos disponibles que podrÃ­an ser relevantes:")
                for item in todos_archivos:
                    if not item.get('folder'):
                        nombre = item.get('name', '')
                        if any(char.isdigit() for char in nombre):  # Si contiene nÃºmeros
                            st.write(f"ðŸ¤” {nombre}")
                
                return None
        else:
            st.error(f"âŒ No se pudo listar el contenido de la carpeta. HTTP {response_list.status_code}")
            return None
            
    except requests.exceptions.RequestException as e:
        st.error(f"Error de conexiÃ³n al buscar el archivo del mes: {e.response.text if e.response else e}")
        return None
    except Exception as e:
        st.error(f"Error inesperado durante la bÃºsqueda del mes: {e}")
        return None

def agregar_datos_a_excel_sharepoint(headers, site_id, ruta_archivo, df_nuevos_datos, status_placeholder):
    st.info(f"ðŸ”„ Actualizando el archivo en SharePoint: '{ruta_archivo.split('/')[-1]}'")
    
    try:
        # PASO 1: Verificar que el archivo existe y obtener metadatos
        st.write("1/4 - Verificando archivo existente...")
        existe, metadata = verificar_archivo_existe_sharepoint(headers, site_id, ruta_archivo)
        
        if not existe:
            st.error("âŒ No se puede continuar: el archivo no existe o no es accesible")
            return False
        
        # PASO 2: Descargar archivo con validaciones
        st.write("2/4 - Descargando archivo existente...")
        contenido_archivo = obtener_contenido_archivo_sharepoint(headers, site_id, ruta_archivo)
        
        if contenido_archivo is None:
            st.error("âŒ No se pudo descargar el archivo")
            return False
        
        # PASO 3: Intentar leer el Excel con manejo de errores mejorado
        st.write("3/4 - Leyendo archivo Excel...")
        try:
            df_existente = pd.read_excel(io.BytesIO(contenido_archivo), engine='openpyxl')
            st.success(f"âœ… Archivo Excel leÃ­do correctamente. Filas existentes: {len(df_existente)}")
        except zipfile.BadZipFile:
            st.error("âŒ Error: El archivo descargado no es un Excel vÃ¡lido")
            st.error("Esto puede indicar que el archivo estÃ¡ corrupto o es de otro tipo")
            return False
        except Exception as e:
            st.error(f"âŒ Error al leer el archivo Excel: {e}")
            return False
        
        # PASO 4: Combinar datos
        st.write("4/4 - Combinando y subiendo datos...")
        df_combinado = pd.concat([df_existente, df_nuevos_datos], ignore_index=True)
        st.success(f"âœ… Datos combinados. Total de filas: {len(df_combinado)}")
        
        # Generar archivo Excel actualizado
        output = io.BytesIO()
        df_combinado.to_excel(output, index=False, engine='xlsxwriter')
        output.seek(0)  # Importante: volver al inicio del buffer
        
        # Subir archivo actualizado
        endpoint_put = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_archivo}:/content"
        headers_upload = headers.copy()
        headers_upload['Content-Type'] = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        
        response_put = requests.put(endpoint_put, data=output.getvalue(), headers=headers_upload)
        
        if response_put.status_code in [200, 201]:
            st.success("ðŸŽ‰ Â¡Ã‰xito! El archivo ha sido actualizado en SharePoint.")
            return True
        else:
            st.error(f"âŒ Error al subir archivo. HTTP {response_put.status_code}")
            try:
                error_json = response_put.json()
                st.json(error_json)
            except:
                st.error(f"Respuesta: {response_put.text}")
            return False
            
    except Exception as e:
        st.error(f"âŒ Error inesperado en la funciÃ³n: {e}")
        return False

def listar_archivos_en_carpeta(headers, site_id, ruta_carpeta):
    """
    Lista todos los archivos en una carpeta para debug
    """
    st.info(f"ðŸ“‚ Explorando carpeta: {ruta_carpeta}")
    
    endpoint = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{ruta_carpeta}:/children"
    
    try:
        response = requests.get(endpoint, headers=headers)
        if response.status_code == 200:
            items = response.json().get('value', [])
            
            st.write(f"ðŸ“Š Encontrados {len(items)} elementos:")
            for item in items:
                tipo = "ðŸ“" if item.get('folder') else "ðŸ“„"
                nombre = item.get('name', 'Sin nombre')
                tamano = item.get('size', 0)
                st.write(f"{tipo} {nombre} ({tamano:,} bytes)")
        else:
            st.error(f"âŒ No se pudo listar la carpeta. HTTP {response.status_code}")
    except Exception as e:
        st.error(f"âŒ Error: {e}")
    
    
# --- FunciÃ³n Principal de Procesamiento ---
def procesar_excel_para_streamlit(uploaded_file, status_placeholder):
    """
    Procesa el archivo de Excel subido:
    - Ignora las primeras 7 filas al cargar el archivo (asumiendo que los encabezados estÃ¡n en la fila 8).
    - Elimina filas con 'Tipo clasificaciÃ³n' vacÃ­o.
    - Elimina columnas no deseadas.
    - Actualiza la columna 'Total'.
    - Rellena 'Tasa de cambio' con TRM de API bajo condiciones especÃ­ficas.

    Args:
        uploaded_file (streamlit.UploadedFile): El archivo Excel subido por el usuario.

    Returns:
        pandas.DataFrame or None: El DataFrame procesado o None si hay un error.
    """
    try:
        # Usar skiprows para que Pandas lea el encabezado correcto
        df = pd.read_excel(uploaded_file, skiprows=7) # La fila 8 (Ã­ndice 7) se toma como encabezado

        # Verifica si el DataFrame tiene columnas despuÃ©s de skiprows.
        if df.empty or df.columns.empty:
            st.error("Parece que el archivo no tiene datos o encabezados despuÃ©s de saltar las primeras 7 filas. Por favor, verifica el formato del archivo.")
            return None

        st.info(f"Archivo cargado exitosamente. Se saltaron las primeras 7 filas. Filas iniciales (despuÃ©s de saltar): **{len(df)}**.")

        df_procesado = df.copy()
        
        # --- FUNCIÃ“N DE LIMPIEZA SIMPLE ---
        def convertir_a_numero_limpiando_comas(columna):
            if not pd.api.types.is_string_dtype(columna):
                columna = columna.astype(str)
            columna_limpia = columna.str.replace(',', '', regex=False)
            return pd.to_numeric(columna_limpia, errors='coerce')

        # Columnas a eliminar predefinidas
        nombres_columnas_a_eliminar = [
            "Sucursal",
            "Centro costo",
            "Fecha creaciÃ³n",
            "Fecha modificaciÃ³n",
            "Correo electrÃ³nico",
            "Tipo de registro",
            "Referencia fÃ¡brica",
            "Bodega",
            "IdentificaciÃ³n Vendedor",
            "Nombre vendedor",
            "Valor desc.",
            "Base AIU",
            "Impuesto cargo",
            "Valor Impuesto Cargo",
            "Impuesto Cargo 2",
            "Valor Impuesto Cargo 2",
            "Impuesto retenciÃ³n",
            "Valor Impuesto RetenciÃ³n",
            "Base retenciÃ³n (ICA/IVA)",
            "Cargo en totales",
            "Descuento en totales",
            "Moneda",
            "Forma pago",
            "Fecha vencimiento",
            "Nombre contacto"
        ]

        df_procesado = df.copy()

        # 1. Eliminar filas donde "Tipo clasificaciÃ³n" estÃ© vacÃ­o/NaN
        if "Tipo clasificaciÃ³n" in df_procesado.columns:
            filas_antes_eliminacion = len(df_procesado)
            df_procesado.dropna(subset=["Tipo clasificaciÃ³n"], inplace=True)
            filas_despues_eliminacion = len(df_procesado)
            st.success(f"Filas con 'Tipo clasificaciÃ³n' vacÃ­o eliminadas: **{filas_antes_eliminacion - filas_despues_eliminacion}**. Filas restantes: **{filas_despues_eliminacion}**.")
        else:
            st.warning("La columna **'Tipo clasificaciÃ³n'** no se encontrÃ³. No se eliminaron filas vacÃ­as.")

        # 2. Eliminar columnas especificadas
        columnas_existentes_para_eliminar = [col for col in nombres_columnas_a_eliminar if col in df_procesado.columns]
        columnas_no_existentes_para_eliminar = [col for col in nombres_columnas_a_eliminar if col not in df_procesado.columns]

        if columnas_existentes_para_eliminar:
            df_procesado.drop(columns=columnas_existentes_para_eliminar, inplace=True)
            st.success(f"Columnas eliminadas: **{', '.join(columnas_existentes_para_eliminar)}**.")
        else:
            st.info("Ninguna de las columnas especificadas para eliminar se encontrÃ³. No se eliminaron columnas.")

        if columnas_no_existentes_para_eliminar:
            st.warning(f"Advertencia: Las siguientes columnas especificadas para eliminaciÃ³n no se encontraron: **{', '.join(columnas_no_existentes_para_eliminar)}**.")

        # 3. Actualizar la columna "Total" existente
        if "Cantidad" in df_procesado.columns and "Valor unitario" in df_procesado.columns and "Total" in df_procesado.columns:
            df_procesado["Cantidad"] = pd.to_numeric(df_procesado["Cantidad"], errors='coerce')
            df_procesado["Valor unitario"] = pd.to_numeric(df_procesado["Valor unitario"], errors='coerce')
            df_procesado["Total"] = df_procesado["Cantidad"] * df_procesado["Valor unitario"]
            df_procesado["Total"] = df_procesado["Total"].fillna(0)
            st.success("La columna **'Total'** ha sido actualizada con el cÃ¡lculo **'Cantidad * Valor unitario'**.")
        else:
            st.warning("Advertencia: No se pudieron encontrar las columnas **'Cantidad'**, **'Valor unitario'** y/o **'Total'**. La columna **'Total'** no se actualizÃ³.")

        # 4. Crear y posicionar la nueva columna "Numero comprobante"
        columnas_necesarias = ['NÃºmero comprobante', 'Consecutivo', 'Factura proveedor']
        if all(col in df_procesado.columns for col in columnas_necesarias):
            # Definir las condiciones
            conditions = [
                df_procesado['NÃºmero comprobante'] == 'FV-1',
                df_procesado['NÃºmero comprobante'] == 'FV-2'
            ]
            
            # Definir los valores a asignar para cada condiciÃ³n
            choices = [
                'FLE-' + df_procesado['Consecutivo'].astype('Int64').astype(str),
                'FSE-' + df_procesado['Consecutivo'].astype('Int64').astype(str)
            ]
            
            # Usar np.select para crear los valores de la nueva columna
            # El valor por defecto serÃ¡ un texto vacÃ­o ''
            valores_nueva_columna = np.select(conditions, choices, default='')
            
            # Encontrar la posiciÃ³n de la columna "Factura proveedor" para insertar antes
            posicion_insercion = df_procesado.columns.get_loc('Factura proveedor')
            
            # Insertar la nueva columna en la posiciÃ³n encontrada
            df_procesado.insert(posicion_insercion, 'Numero comprobante', valores_nueva_columna)
            
            st.success("Se ha creado y llenado la nueva columna **'Numero comprobante'**.")
            
        else:
            st.warning("Advertencia: No se encontraron las columnas necesarias ('NÃºmero comprobante', 'Consecutivo', 'Factura proveedor') para crear la nueva columna.")
        
        # 5. Extraer TRM de 'Observaciones' y sobrescribir 'Tasa de cambio'
        #if "Tasa de cambio" in df_procesado.columns and "Observaciones" in df_procesado.columns:
            #st.info("Actualizando 'Tasa de cambio' con los valores encontrados en 'Observaciones'...")

            #df_procesado['Observaciones'] = df_procesado['Observaciones'].astype(str)
            # Extrae el contenido de las llaves '{}'. El resultado serÃ¡ el texto o NaN si no hay llaves.
            #trm_extraida = df_procesado['Observaciones'].str.extract(r'\{(.*?)\}')[0]
            # Elimina las filas donde no se encontrÃ³ nada (NaN), para quedarnos solo con los valores a actualizar.
            #trm_extraida.dropna(inplace=True)
            # Aseguramos que la columna 'Tasa de cambio' pueda recibir texto sin problemas.
            #df_procesado['Tasa de cambio'] = df_procesado['Tasa de cambio'].astype(object)
            # Actualiza la columna 'Tasa de cambio' SÃ“LO con los valores encontrados.
            # El mÃ©todo .update() alinea por Ã­ndice y solo modifica donde hay coincidencia.
            #df_procesado['Tasa de cambio'].update(trm_extraida)
            
            #filas_actualizadas = len(trm_extraida)
            #st.success(f"Se actualizaron **{filas_actualizadas}** filas en 'Tasa de cambio'. Los valores existentes se respetaron donde no se encontrÃ³ un valor entre {{}}.")
        #else:
            #st.warning("Advertencia: No se encontraron las columnas **'Tasa de cambio'** y/o **'Observaciones'**.")
        # 5. Extraer, LIMPIAR y sobrescribir 'Tasa de cambio' desde 'Observaciones' (LÃ“GICA CORREGIDA Y ENFOCADA)
        if "Tasa de cambio" in df_procesado.columns and "Observaciones" in df_procesado.columns:
            
            # Para evitar problemas, nos aseguramos de que la columna 'Tasa de cambio' sea numÃ©rica desde el principio.
            # Usamos la limpieza simple de comas que ya definimos.
            df_procesado['Tasa de cambio'] = convertir_a_numero_limpiando_comas(df_procesado['Tasa de cambio']).fillna(0)

            # 1. EXTRAER el valor de las observaciones como texto.
            trm_extraida = df_procesado['Observaciones'].astype(str).str.extract(r'\{(.*?)\}')[0]
            
            # Quitamos las filas donde no se encontrÃ³ nada.
            trm_extraida.dropna(inplace=True)

            if not trm_extraida.empty:
                st.info("Valores de TRM encontrados en 'Observaciones'. Limpiando y actualizando...")

                # 2. LIMPIAR el texto extraÃ­do (quitamos comas de miles).
                # Ejemplo: "4,061.36" se convierte en "4061.36"
                trm_limpia = trm_extraida.str.replace(',', '', regex=False)

                # 3. CONVERTIR el texto limpio a un formato numÃ©rico.
                trm_numerica = pd.to_numeric(trm_limpia, errors='coerce')
                
                # Quitamos las filas donde la conversiÃ³n a nÃºmero pudo haber fallado.
                trm_numerica.dropna(inplace=True)

                # 4. ACTUALIZAR la columna 'Tasa de cambio' con los valores ya numÃ©ricos y limpios.
                # El mÃ©todo .update() alinea por Ã­ndice y solo modifica donde encuentra correspondencia.
                df_procesado['Tasa de cambio'].update(trm_numerica)
                st.success(f"Se actualizaron **{len(trm_numerica)}** filas en 'Tasa de cambio' con valores numÃ©ricos limpios desde 'Observaciones'.")


        # 5.1. Calcular la nueva columna 'Valor Total ME' (VERSIÃ“N CORREGIDA FINAL)
        st.info("Calculando 'Valor Total ME'...")
        if 'Total' in df_procesado.columns and 'Tasa de cambio' in df_procesado.columns:
            
            # PASO CLAVE: Nos aseguramos de que 'Tasa de cambio' sea numÃ©rica OTRA VEZ,
            # justo antes de la divisiÃ³n, para revertir el cambio a 'object' del paso anterior.
            tasa_numerica = pd.to_numeric(df_procesado['Tasa de cambio'], errors='coerce')
            
            # Reemplazamos 0 con NaN para evitar errores de divisiÃ³n por cero.
            tasa_numerica.replace(0, np.nan, inplace=True)

            # Realizamos la divisiÃ³n.
            df_procesado['Valor Total ME'] = df_procesado['Total'] / tasa_numerica
            
            # Rellenamos cualquier resultado invÃ¡lido (NaN) con 0.
            df_procesado['Valor Total ME'].fillna(0, inplace=True)
            
            st.success("Se ha creado y calculado la columna **'Valor Total ME'**.")
        else:
            st.warning("No se pudo calcular 'Valor Total ME'.")

        # 6. Relacionar documentos FV-1 con DS-1 y FC-1
        st.info("Iniciando el proceso de relacionamiento de documentos...")
        
        # Separar el DataFrame en los dos grupos principales
        df_destino = df_procesado[df_procesado['NÃºmero comprobante'].isin(['FV-1', 'FV-2'])].copy()
        df_fuente = df_procesado[df_procesado['NÃºmero comprobante'].isin(['DS-1', 'FC-1'])].copy()

        if not df_fuente.empty:
            # Preparar el DataFrame fuente (DS-1, FC-1)
            df_fuente['NIT_relacion'] = df_fuente['Observaciones'].str.extract(r'\((.*?)\)')[0]
            
            df_destino['IdentificaciÃ³n'] = df_destino['IdentificaciÃ³n'].astype('Int64').astype(str)
            df_destino['CÃ³digo'] = df_destino['CÃ³digo'].astype(str)
            
            df_fuente['NIT_relacion'] = df_fuente['NIT_relacion'].astype(str)
            df_fuente['CÃ³digo'] = df_fuente['CÃ³digo'].astype(str)
            
            # AÃ±adir prefijo a las columnas para evitar colisiones y dar claridad
            df_fuente = df_fuente.add_prefix('REL_')
            
            # Realizar la uniÃ³n externa (outer join)
            df_final = pd.merge(
                df_destino,
                df_fuente,
                how='outer',
                left_on=['IdentificaciÃ³n', 'CÃ³digo'],
                right_on=['REL_NIT_relacion', 'REL_CÃ³digo']
            )
            
            st.success("Relacionamiento completado. Los documentos sin pareja se han conservado.")
            df_procesado = df_final
        else:
            st.warning("No se encontraron documentos DS-1 o FC-1 para relacionar. El archivo final no tendrÃ¡ columnas de relaciÃ³n.")
        
        # 7. Organizar y Limpiar Columnas Finales
        st.info("Organizando el formato final del archivo...")
        
        # A. Renombrar la columna "Tipo clasificaciÃ³n" a "Tipo Bien"
        # Verificamos si la columna existe antes de intentar renombrarla
        if "Tipo clasificaciÃ³n" in df_procesado.columns:
            df_procesado.rename(columns={"Tipo clasificaciÃ³n": "Tipo Bien"}, inplace=True)
            st.info("La columna **'Tipo clasificaciÃ³n'** ha sido renombrada a **'Tipo Bien'**.")
        
        if 'Tipo Bien' in df_procesado.columns:
            # Creamos un diccionario con los valores a reemplazar
            mapeo_valores = {
                'Servicio': 'S',
                'Producto': 'P'
            }
            df_procesado['Tipo Bien'].replace(mapeo_valores, inplace=True)
            st.info("Valores en 'Tipo Bien' actualizados: 'Servicio' a 'S' y 'Producto' a 'P'.")
        
        #CreaciÃ³n de la nueva columna "Vendedor"
        if 'Vendedor' not in df_procesado.columns:
            df_procesado['Vendedor'] = ''
            
        #CreaciÃ³n de la nueva columna "ClasificaciÃ³n Producto"
        if 'ClasificaciÃ³n Producto' not in df_procesado.columns:
            df_procesado['ClasificaciÃ³n Producto'] = ''
            
        #CreaciÃ³n de la nueva columna "LÃ­nea"
        if 'LÃ­nea' not in df_procesado.columns:
            df_procesado['LÃ­nea'] = ''
            
        #CreaciÃ³n de la nueva columna "DescripciÃ³n LÃ­nea"
        if 'DescripciÃ³n LÃ­nea' not in df_procesado.columns:
            df_procesado['DescripciÃ³n LÃ­nea'] = ''
            
        #CreaciÃ³n de la nueva columna "SublÃ­nea"
        if 'SublÃ­nea' not in df_procesado.columns:
            df_procesado['SublÃ­nea'] = ''
            
        #CreaciÃ³n de la nueva columna "DescripciÃ³n SublÃ­nea"
        if 'DescripciÃ³n SublÃ­nea' not in df_procesado.columns:
            df_procesado['DescripciÃ³n SublÃ­nea'] = ''
            
        
        #Se define el orden y la selecciÃ³n final de las columnas
        columnas_finales = [
            # Columnas del lado izquierdo (FV)
            'Tipo Bien', 'ClasificaciÃ³n Producto', 'LÃ­nea', 'DescripciÃ³n LÃ­nea', 'SublÃ­nea', 'DescripciÃ³n SublÃ­nea', 'CÃ³digo', 'Nombre', 'NÃºmero comprobante', 'Numero comprobante',
            'Fecha elaboraciÃ³n', 'IdentificaciÃ³n', 'Nombre tercero', 'Vendedor', 'Cantidad',
            'Valor unitario', 'Total', 'Tasa de cambio', 'Valor Total ME', 'Observaciones',
            
            # Columnas del lado derecho (REL_)
            'REL_NÃºmero comprobante', 'REL_Consecutivo',
            'REL_Factura proveedor', 'REL_IdentificaciÃ³n', 'REL_Nombre tercero', 'REL_Cantidad',
            'REL_Valor unitario',  'REL_Tasa de cambio', 'REL_Total', 'REL_Valor Total ME'
        ]
        
        # Filtrar la lista para incluir solo las columnas que realmente existen en el DataFrame
        # Esto hace el cÃ³digo mÃ¡s robusto si alguna columna faltara
        columnas_existentes_ordenadas = [col for col in columnas_finales if col in df_procesado.columns]

        # Reordenar y eliminar las columnas no deseadas de una sola vez
        df_procesado = df_procesado[columnas_existentes_ordenadas]

        st.success("Columnas reorganizadas y limpiadas con Ã©xito.")
 
        st.success("Â¡Procesamiento completado con Ã©xito!")
        
        return df_procesado

    except Exception as e:
        st.error(f"Se produjo un error durante el procesamiento: {e}")
        return None

# --- Interfaz de Usuario de Streamlit ---
st.set_page_config(page_title="Procesador de Excel AutomÃ¡tico", layout="centered")

st.title("ðŸ“Š Procesador de Archivos Excel")
st.markdown("---")

uploaded_file = st.file_uploader(
    "Sube tu archivo Excel (.xlsx)",
    type=["xlsx"],
    help="Arrastra y suelta tu archivo Excel aquÃ­ o haz clic para buscar."
)

st.markdown("---")
st.header("ðŸ”§ Herramientas de Debug para SharePoint")

# Crear variables de prueba para conexiÃ³n SharePoint
if st.button("ðŸ”— Probar ConexiÃ³n SharePoint (Solo Debug)"):
    with st.spinner("Conectando..."):
        status_placeholder = st.empty()
        token = get_access_token(status_placeholder)
        
        if token:
            site_id = get_sharepoint_site_id(token)
            if site_id:
                headers = {'Authorization': f'Bearer {token}'}
                st.session_state.debug_headers = headers
                st.session_state.debug_site_id = site_id
                st.success("âœ… ConexiÃ³n establecida para debug")

# Solo mostrar herramientas de debug si hay conexiÃ³n
if hasattr(st.session_state, 'debug_headers') and hasattr(st.session_state, 'debug_site_id'):
    
    with st.expander("ðŸ§ª Debug de Archivos SharePoint", expanded=False):
        
        # Debug para la carpeta mensual
        st.subheader("ðŸ“… Debug de Carpeta Mensual")
        if st.button("Listar archivos en carpeta mensual"):
            listar_archivos_en_carpeta(st.session_state.debug_headers, st.session_state.debug_site_id, "Ventas con ciudad 2025")
        
        # Debug para archivo especÃ­fico
        st.subheader("ðŸ” Debug de Archivo EspecÃ­fico")
        archivo_debug = st.text_input("Ruta completa del archivo a verificar:", 
                                     "Ventas con ciudad 2025/Ventas Septiembre 2025.xlsx")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Verificar archivo"):
                if archivo_debug:
                    verificar_archivo_existe_sharepoint(st.session_state.debug_headers, st.session_state.debug_site_id, archivo_debug)
        
        with col2:
            if st.button("Intentar descargar"):
                if archivo_debug:
                    contenido = obtener_contenido_archivo_sharepoint(st.session_state.debug_headers, st.session_state.debug_site_id, archivo_debug)
                    if contenido:
                        st.success(f"Archivo descargado exitosamente ({len(contenido):,} bytes)")

st.markdown("---")

df_result = None


if uploaded_file is not None:
    st.success(f"Archivo **'{uploaded_file.name}'** cargado correctamente.")
    
    if st.button("Iniciar Procesamiento"):
        # Crear el placeholder una sola vez
        status_placeholder = st.empty()
        with st.spinner("Procesando tu archivo... Esto puede tardar unos minutos, especialmente al consultar la TRM..."):
            df_result = procesar_excel_para_streamlit(uploaded_file, status_placeholder)
        
        if df_result is not None:
            st.subheader("Vista previa del archivo procesado:")
            st.dataframe(df_result.head())

            output = io.BytesIO()
            # 2. Conectarse a SharePoint
            token = get_access_token(status_placeholder)
            if token:
                
                site_id = get_sharepoint_site_id(token) # Esta funciÃ³n es rÃ¡pida, no necesita placeholder

                if site_id:
                    # Una vez que tenemos el site_id, AHORA creamos los headers para las siguientes funciones
                    headers = {'Authorization': f'Bearer {token}'}
                    # 3. Encontrar el archivo del mes
                    ruta_archivo_mensual = encontrar_archivo_del_mes(headers, site_id, RUTA_CARPETA_VENTAS_MENSUALES, status_placeholder)
                    ruta_fija_trm = "01 Archivos Area Administrativa/TRM.xlsx"
                    exito_trm = actualizar_archivo_trm(headers, site_id, ruta_fija_trm, df_result, status_placeholder)
                    st.info("Archivo TRM actualizado con Ã‰xito")
                    if ruta_archivo_mensual:
                        # 4. Agregar los datos
                        #agregar_datos_a_excel_sharepoint(headers, site_id, ruta_archivo_mensual, df_result, status_placeholder)
                        exito = agregar_datos_a_excel_sharepoint(headers, site_id, ruta_archivo_mensual, df_result, status_placeholder)
                        if exito:
                            st.balloons()
            
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df_result.to_excel(writer, index=False, sheet_name='Procesado')
            processed_data = output.getvalue()

            st.download_button(
                label="Descargar Archivo Procesado",
                data=processed_data,
                file_name=f"procesado_{uploaded_file.name}",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            st.info("Tu archivo ha sido procesado y estÃ¡ listo para descargar.")
else:
    st.info("Por favor, sube un archivo Excel para comenzar.")
    
    



